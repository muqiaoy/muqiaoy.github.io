

<!DOCTYPE html>
<html data-wf-domain="http://muqiaoy.github.io/usee">
<head>

  <!-- for Google Analytics, contact Basile -->
  <!-- Google site tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-TVMSEDK6MV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-TVMSEDK6MV');
  </script>

  <meta charset="utf-8"/>
  <title>uSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models</title>
  <meta content="uSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models" name="description"/>
  <meta content="summary" name="twitter:card"/><meta content="width=device-width, initial-scale=1" name="viewport"/>
  <link href="style/template.css" rel="stylesheet" type="text/css"/>
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">WebFont.load({  google: {    families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic","Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic","Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic","Changa One:400,400italic","Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic","Varela Round:400","Bungee Shade:regular","Roboto:300,regular,500"]  }});</script>
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
<!--   <link href="images/logo.png" rel="shortcut icon" type="image/x-icon"/>
  <link href="images/logo.png" rel="apple-touch-icon"/> -->
  <style>
    .wf-loading * {
        opacity: 0;
    }
  </style>
  <!-- <meta charset="utf-8"> -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
  <!-- <meta name="description" content="">
  <meta name="author" content=""> -->

  <script
    type="module"
    src="style/model-viewer.min.js"
  ></script>
  <style>
    model-viewer {
      cursor: grab;
      display: flex;
      height: 100%;
      width: 100%;
      overflow: hidden;
      position: relative;
      user-select: none;
    }
  </style>
  <link rel="stylesheet" href="style/bootstrap.min.css">
  <link rel="stylesheet" href="style/style.css">

</head>

<body>
  
<div class="section hero nerf-_v2">
    <div class="container-2 nerf_header_v2 w-container">
      <h1 class="nerf_title_v2">uSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models</h1>
      <div class="container-2 nerf_header_v2 w-container">
      <div class="nerf_authors_list_single w-row">
        <div class="w-col-2 w-col w-col-small-2 w-col-tiny-2">
          <a href="https://muqiaoy.github.io/" target="_blank" class="nerf_authors_v2">Muqiao Yang
          </a>
        </div>
        <div class="w-col-2 w-col w-col-small-4 w-col-tiny-4">
          <a href="https://scholar.google.com/citations?user=NCKZGb0AAAAJ&hl=zh-CN" target="_blank" class="nerf_authors_v2">Chunlei Zhang
          </a>
        </div>
        <div class="w-col-2 w-col w-col-small-4 w-col-tiny-4">
          <a href="https://sites.google.com/view/xuyong/home" target="_blank" class="nerf_authors_v2">Yong Xu
          </a>
        </div>
        <div class="w-col-2 w-col w-col-small-4 w-col-tiny-4">
          <a href="https://xzwy.github.io/alanweiyang.github.io/" target="_blank" class="nerf_authors_v2">Zhongweiyang Xu
          </a>
        </div>
        <div class="w-col-2 w-col w-col-small-4 w-col-tiny-4">
          <a href="https://whmrtm.github.io/" target="_blank" class="nerf_authors_v2">Heming Wang
          </a>
        </div>
        <div class="w-col-2 w-col w-col-small-4 w-col-tiny-4">
          <a href="http://mlsp.cs.cmu.edu/people/bhiksha/" target="_blank" class="nerf_authors_v2">Bhiksha Raj
          </a>
        </div>
        <div class="w-col-2 w-col w-col-small-4 w-col-tiny-4">
          <a href="https://sites.google.com/view/dongyu888/" target="_blank" class="nerf_authors_v2">Dong Yu
          </a>
        </div>
      </div>
      <div class="nerf_authors_list_single nerf_authors_affiliation w-row">
        <div class="w-col-2 w-col"><h1 class="nerf_affiliation_v2">CMU</h1></div>
        <div class="w-col-2 w-col"><h1 class="nerf_affiliation_v2">Tencent</h1></div>
        <div class="w-col-2 w-col"><h1 class="nerf_affiliation_v2">Tencent</h1></div>
        <div class="w-col-2 w-col"><h1 class="nerf_affiliation_v2">UIUC</h1></div>
        <div class="w-col-2 w-col"><h1 class="nerf_affiliation_v2">OSU</h1></div>
        <div class="w-col-2 w-col"><h1 class="nerf_affiliation_v2">CMU</h1></div>
        <div class="w-col-2 w-col"><h1 class="nerf_affiliation_v2">Tencent</h1></div>
      </div>
      <h2 class="tldr">TL;DR: We build a Unified Speech Enhancement and Editing (uSee) framework with conditional diffusion models to enable fine-grained controllable generation based on both acoustic and textual prompts.</h2>
      <div>
        <span class="center"><img src="assets/teaser.png" style="width:900px;"></span>
      </div>
<!--        <div class="w-row">
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <a href="https://arxiv.org/abs/2303.11328" target="_blank" class="link-block w-inline-block">
              <img src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cab99df4998decfbf9e218e_paper-01.png" alt="paper" class="paper_img image-8 github_icon_nerf_v2"/></a>
          </div>
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <a href="https://github.com/cvlab-columbia/zero123" target="_blank" class="link-block w-inline-block">
            <img src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5cae3b53b42ebb3dd4175a82_68747470733a2f2f7777772e69636f6e66696e6465722e636f6d2f646174612f69636f6e732f6f637469636f6e732f313032342f6d61726b2d6769746875622d3235362e706e67.png" alt="github" class="paper_img image-8 github_icon_nerf_v2"/></a>
          </div>
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <a href="https://huggingface.co/spaces/cvlab/zero123-live" target="_blank" class="link-block w-inline-block">
            <img src="assets/hf.jpg"  alt="demo" class="paper_img image-8_nerf nerf_db_icon"/></a>
          </div>
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <a href="https://huggingface.co/cvlab/zero123-weights/tree/main" target="_blank" class="link-block w-inline-block">
            <img src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/5e7136849ee3b0a0c6a95151_database.svg" alt="model" class="paper_img image-8_nerf nerf_db_icon"/></a>
          </div>
        </div>
         <div class="w-row">
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <div class="text-block-2"><strong class="bold-text-nerf_v2">Arxiv</strong></div>
          </div>
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <div class="text-block-2"><strong class="bold-text-nerf_v2">Code</strong></div>
          </div>
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <div class="text-block-2"><strong class="bold-text-nerf_v2">Live Demo</strong></div>
          </div>
          <div class="w-col w-col-3 w-col-small-4 w-col-tiny-4">
            <div class="text-block-2"><strong class="bold-text-nerf_v2">Pretrained models</strong></div>
          </div>
        </div> -->
    </div>
  </div>
</div>

<div class="white_section_nerf">
  <div class="grey_container w-container">
  <h2 class="grey-heading_nerf">Abstract</h2>
  <p class="paragraph-3 nerf_text nerf_results_text">
In this paper, we propose a <span class="bolded">Unified Speech Enhancement and Editing (uSee)</span> model with conditional diffusion models to handle various tasks at the same time in a generative manner. Specifically, by providing multiple types of conditions including self-supervised learning embeddings and proper text prompts to the score-based diffusion model, we can enable controllable generation of the unified speech enhancement and editing model to perform corresponding actions on the source speech. Our experiments show that our proposed uSee model can achieve superior performance in both speech denoising and dereverberation compared to other related generative speech enhancement models, and can perform speech editing given desired environmental sound text description, signal-to-noise ratios (SNR), and room impulse responses (RIR).
  </p>
</div>
</div>


<div class="white_section_nerf">
  <div class="w-container">
  <h2 class="grey-heading_nerf">Demo: Speech Enhancement</h2>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Source <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/enhan_src1.wav" type="audio/wav" />
                                                </audio></td><br>
        Target <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/enhan_tgt1.wav" type="audio/wav" />
                                                </audio></td>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Source <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/enhan_src2.wav" type="audio/wav" />
                                                </audio></td><br>
        Target <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/enhan_tgt2.wav" type="audio/wav" />
                                                </audio></td>
      </p>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Source <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/enhan_src3.wav" type="audio/wav" />
                                                </audio></td><br>
        Target <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/enhan_tgt3.wav" type="audio/wav" />
                                                </audio></td>
      </p>
  </div>
</div>

<div class="white_section_nerf">
  <div class="w-container">
  <h2 class="grey-heading_nerf">Demo: Speech Editing</h2>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Example sound <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/chirp.wav" type="audio/wav" />
                                                </audio></td><br>
        Target (Add bird chirp) <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/edit_chirp.wav" type="audio/wav" />
                                                </audio></td>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Example sound <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/hardRock.wav" type="audio/wav" />
                                                </audio></td><br>
        Target (Add hard rock)<br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/edit_hardrock.wav" type="audio/wav" />
                                                </audio></td>
      </p>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Example sound <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/Happy_Hour.wav" type="audio/wav" />
                                                </audio></td><br>
        Target (Add happy hour)<br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/edit_happyhour.wav" type="audio/wav" />
                                                </audio></td>
      </p>
      <br></br>
      <p class="paragraph-3 nerf_text nerf_results_text">
        Raw audio <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/no_reverb.wav" type="audio/wav" />
                                                </audio></td><br>
      </p>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Add small room RIR <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/smallroom.wav" type="audio/wav" />
                                                </audio></td><br>
      </p>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Add medium room RIR <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/mediumroom.wav" type="audio/wav" />
                                                </audio></td><br>
      </p>
      <p class="paragraph-3 nerf_text nerf_results_text" style="display:inline-block">
        Add large room RIR <br>
        <td><audio class="audio-player" style="width: 260px;" preload="metadata" controls="controls">
                                                <source src="resource/largeroom.wav" type="audio/wav" />
                                                </audio></td><br>
      </p>
  </div>
</div>



<div class="white_section_nerf">
  <div class="w-container">
  <h2 class="grey-heading_nerf">BibTeX</h2>
  <div class="grey_container w-container">
    <div class="bibtex">
     <pre><code>@article{yang2023usee,
  title={uSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models},
  author={Yang, Muqiao and Zhang, Chunlei and Xu, Yong and Xu, Zhongweiyang and Wang, Heming and Raj, Bhiksha and Yu, Dong},
  journal={arXiv preprint arXiv:2310.00900},
  year={2023}
}</code></pre>
    </div>
    </div>
    </div>
    </div>

</body></html>
